defaults:
  - _self_
  - rewards:
    - action_penalty
    - object_pos_err

name: warp_claw_old

env:
  _target_: dmanip.envs.ClawWarpEnvOld
  num_envs: ${resolve_default:256,${...num_envs}}
  episode_length: 500
  render: ${render}
  no_grad: ???
  # rew_params: 
  #   action_penalty: ${...rewards.action_penalty}
  #   object_pos_err: ${...rewards.object_pos_err}
  #   object_joint_pos_err: ${...rewards.object_joint_pos_err}
  stochastic_init: true
  seed: ${general.seed}
  action_type: ${action:torque}
  action_strength: 10.0
  object_type: ${object:octprism}
  goal_type: ${goal:orientation}
  reward_type: ${reward:delta}
  debug: ${debug}

shac:
  steps_num: 25
  actor_lr: 2e-3
  critic_lr: 4e-3
  actor: ActorStochasticMLP # ActorDeterministicMLP
  actor_mlp:
    units: [128, 64, 32]
    activation: elu

  critic: CriticMLP
  critic_mlp:
    units: [64, 64]
    activation: elu


ppo:
  max_epochs: 500
  minibatch_size: 1920
  save_interval: 100
  save_best_after: 50
  num_actors: 32
  steps_num: 240

player:
  deterministic: True
  games_num: 12
  num_actors: 4
  print_stats: True
