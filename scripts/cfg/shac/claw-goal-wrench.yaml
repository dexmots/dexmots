params:
  diff_env:
    name: ClawWarpEnv
    stochastic_env: False
    episode_length: 256
    goal_type: 6   # 0: position, 1: orientation, 2: both, 3: position trajectory, 4: orientation trajectory
    object_type: 8
    action_type: 2 # 0: position, 1: torque
    goal_path: "goal_traj-sliding-2.npy"
    rew_kw:
      c_act: 0.
      c_q: 10.
      c_finger: 0.2

  network:
    actor: ActorStochasticMLP # ActorDeterministicMLP
    actor_mlp:
      units: [128, 64, 32]
      activation: elu

    critic: CriticMLP
    critic_mlp:
      units: [64, 64]
      activation: elu

  config:
    name: warp_claw_shac
    actor_learning_rate: 2e-3 # adam
    critic_learning_rate: 2e-3 # adam
    lr_schedule: linear # ['constant', 'linear']
    target_critic_alpha: 0.2
    obs_rms: True
    ret_rms: False
    critic_iterations: 16
    critic_method: td-lambda # ['td-lambda', 'one-step']
    lambda: 0.95
    num_batch: 4
    gamma: 0.99
    betas: [0.7, 0.95] # adam
    max_epochs: 1500
    steps_num: 32
    grad_norm: 1.0
    truncate_grads: True
    num_actors: 32
    save_interval: 400
    score_keys: ["control_pen", "ftip_err", "q_err", "pos_err", "force_err"]

    player:
      determenistic: True
      games_num: 1
      num_actors: 1
      print_stats: True
